# TIL

### beomi/KoAlpaca-KoRWKV-1.5B 

> 트랜스포머를 활용한 자연어 처리 5장을 진행중, 영어 모델 (GPT-2)에 대한 문장 생성 능력을 확인해보았는데
> 생성이 꽤 괜찮았다. 더 좋은 형태로 생성할 수 있게 top_p,top_k 등의 샘플링 기법을 적용해서 실습을 진행
> 한국어 모델에 대한 생성 능력도 확인하고 싶어서 진행

### 결과
> 모델의 생성 능력이 좋지 않다. 반복적인 단어를 계속해서 이어서 max_token을 채우는 경향이 있다.
> 5.8B 모델과 비교하니 해당 모델은 잘 나오는것을 확인하였다.
> 1.5B 모델의 성능을 높이기 위해 여러 기법들을 확인하여 적용중

- 문장 생성 형태의 데이터를 학습 시켜 생성 테스트 진행중